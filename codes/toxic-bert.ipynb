{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['docs', 'README.md', 'apex', '.gitignore', 'setup.py', '.nojekyll', 'examples', 'tests', 'csrc', 'LICENSE']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    \"This code is based on the great kernel https://www.kaggle.com/yuval6967/toxic-bert-plain-vanila from yuval\",\n",
    "    \"Modifications include:\"\n",
    "    \"   sequence bucketing, custom loss, multi-label prediction\",\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "print(os.listdir(\"../input/nvidiaapex/repository/NVIDIA-apex-39e153a\"))\n",
    "# Installing Nvidia Apex\n",
    "! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ../input/nvidiaapex/repository/NVIDIA-apex-39e153a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import pkg_resources\n",
    "import seaborn as sns\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "import gc\n",
    "import re\n",
    "import operator \n",
    "import sys\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pickle\n",
    "from apex import amp\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 220\n",
    "SEED = 3234\n",
    "EPOCHS = 1\n",
    "Data_dir=\"../input/jigsaw-unintended-bias-in-toxicity-classification\"\n",
    "Input_dir = \"../input\"\n",
    "WORK_DIR = \"../working/\"\n",
    "# full_length=1804874\n",
    "num_to_load=1754800\n",
    "valid_size= 50000                         #Validation Size\n",
    "# num_to_load=full_length-valid_size                         #Train size to match time limit\n",
    "# num_to_load=20000                         #Train size to match time limit\n",
    "# valid_size= 5000                         #Validation Size\n",
    "TOXICITY_COLUMN = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Bart Pytorch repo to the PATH\n",
    "# using files from: https://github.com/huggingface/pytorch-pretrained-BERT\n",
    "\n",
    "package_dir_a = \"../input/ppbert/pytorch-pretrained-bert/pytorch-pretrained-BERT\"\n",
    "sys.path.insert(0, package_dir_a)\n",
    "\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification,BertAdam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Translate model from tensorflow to pytorch\n",
    "BERT_MODEL_PATH = '../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'\n",
    "convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n",
    "    BERT_MODEL_PATH + 'bert_model.ckpt',\n",
    "BERT_MODEL_PATH + 'bert_config.json',\n",
    "WORK_DIR + 'pytorch_model.bin')\n",
    "\n",
    "shutil.copyfile(BERT_MODEL_PATH + 'bert_config.json', WORK_DIR + 'bert_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the Bert configuration file\n",
    "from pytorch_pretrained_bert import BertConfig\n",
    "\n",
    "bert_config = BertConfig('../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'+'bert_config.json')\n",
    "BERT_MODEL_PATH = '../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the lines to BERT format\n",
    "# Thanks to https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming\n",
    "def convert_lines(example, max_seq_length,tokenizer):\n",
    "    max_seq_length -=2\n",
    "    all_tokens = []\n",
    "    longer = 0\n",
    "    for text in tqdm_notebook(example):\n",
    "        tokens_a = tokenizer.tokenize(text)\n",
    "        if len(tokens_a)>max_seq_length:\n",
    "            tokens_a = tokens_a[:max_seq_length]\n",
    "            longer += 1\n",
    "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n",
    "        all_tokens.append(one_token)\n",
    "    print(longer)\n",
    "    return np.array(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1804800 records\n",
      "CPU times: user 13.2 s, sys: 1.85 s, total: 15 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "chosen_idx = np.random.choice(num_to_load+valid_size,size = num_to_load+valid_size,replace=False) \n",
    "train_df = pd.read_csv(os.path.join(Data_dir,\"train.csv\")).iloc[chosen_idx] \n",
    "# train_df = pd.read_csv(os.path.join(Data_dir,\"train.csv\")).sample(num_to_load+valid_size,random_state=SEED)\n",
    "print('loaded %d records' % len(train_df))\n",
    "\n",
    "# Make sure all comment_text values are strings\n",
    "train_df['comment_text'] = train_df['comment_text'].astype(str)\n",
    "# train_df['comment_text'] = train_df['comment_text'].progress_apply(lambda x:preprocess(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85d70350867457ab8b0d12608ad9b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1804800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%time\n",
    "sequences = convert_lines(train_df[\"comment_text\"].fillna(\"DUMMY_VALUE\"),MAX_SEQUENCE_LENGTH,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.fillna(0)\n",
    "# List all identities\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "x_train = train_df['comment_text']\n",
    "train_df = train_df.drop(['comment_text'],axis=1)\n",
    "# convert target to 0,1\n",
    "train_df['target']=(train_df['target']>=0.5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = sequences[:num_to_load]                \n",
    "# y = train_df[y_columns].values[:num_to_load]\n",
    "X_val = sequences[num_to_load:]                \n",
    "# y_val = train_df[y_columns].values[num_to_load:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall\n",
    "weights = np.ones((len(train_df),)) / 4\n",
    "# Subgroup\n",
    "weights += (train_df[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) / 4\n",
    "# Background Positive, Subgroup Negative\n",
    "weights += (( (train_df['target'].values>=0.5).astype(bool).astype(np.int) +\n",
    "    (train_df[identity_columns].fillna(0).values<0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 4\n",
    "# Background Negative, Subgroup Positive\n",
    "weights += (( (train_df['target'].values<0.5).astype(bool).astype(np.int) +\n",
    "    (train_df[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 4\n",
    "loss_weight = 1.0 / weights.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns=['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat','sexual_explicit']\n",
    "# y_train=np.vstack([train_df['target'],weights]).T\n",
    "# y_train=np.concatenate((y_train,train_df[y_columns]),axis=1)\n",
    "y_train=np.array(train_df[y_columns])\n",
    "y_train = np.hstack((y_train, np.reshape(weights, (-1, 1))))\n",
    "# y_train = np.hstack((y_train, train_df[y_columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = y_train[num_to_load:]\n",
    "y = y_train[:num_to_load]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=train_df.tail(valid_size).copy()\n",
    "train_df=train_df.head(num_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceBucketCollator():\n",
    "    def __init__(self, choose_length, sequence_index, length_index, label_index=None):\n",
    "        self.choose_length = choose_length\n",
    "        self.sequence_index = sequence_index\n",
    "        self.length_index = length_index\n",
    "        self.label_index = label_index\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        batch = [torch.stack(x) for x in list(zip(*batch))]\n",
    "        \n",
    "        sequences = batch[self.sequence_index]\n",
    "        lengths = batch[self.length_index]\n",
    "        \n",
    "        length = self.choose_length(lengths)\n",
    "#         print(length)\n",
    "        mask = torch.arange(start=maxlen, end=0, step=-1) < length\n",
    "        padded_sequences = sequences[:, mask]\n",
    "        \n",
    "        batch[self.sequence_index] = padded_sequences\n",
    "        \n",
    "        if self.label_index is not None:\n",
    "            return [x for i, x in enumerate(batch) if i != self.label_index], batch[self.label_index]\n",
    "    \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(X,dtype=torch.long),torch.tensor(y,dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(data, targets):\n",
    "    ''' Define custom loss function for weighted BCE on 'target' column '''\n",
    "    bce_loss_1 = nn.BCEWithLogitsLoss(weight=targets[:,-1:])(data[:,:1],targets[:,:1])\n",
    "    bce_loss_2 = nn.BCEWithLogitsLoss()(data[:,1:],targets[:,1:-1])\n",
    "    return (bce_loss_1 * loss_weight) + bce_loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # clean garbage\n",
    "del train_df, y_train, sequences, X\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f70d4980df0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_model_file = \"bert_pytorch.bin\"\n",
    "\n",
    "lr=2e-5\n",
    "batch_size = 32\n",
    "accumulation_steps= 1\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"../working\",cache_dir=None,num_labels=7)\n",
    "model.zero_grad()\n",
    "model = model.to(device)\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "train = train_dataset\n",
    "\n",
    "num_train_optimization_steps = int(EPOCHS*len(train)/batch_size/accumulation_steps)\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=lr,\n",
    "                     warmup=0.05,\n",
    "                     t_total=num_train_optimization_steps)\n",
    "\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "model=model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class LenMatchBatchSampler(data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            count_zeros = torch.sum(self.sampler.data_source[idx][0] == 0)\n",
    "            count_zeros = int(count_zeros / 64) \n",
    "            if len(buckets[count_zeros]) == 0:  buckets[count_zeros] = []\n",
    "\n",
    "            buckets[count_zeros].append(idx)\n",
    "\n",
    "            if len(buckets[count_zeros]) == self.batch_size:\n",
    "                batch = list(buckets[count_zeros])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[count_zeros] = []\n",
    "\n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "\n",
    "        assert len(self) == yielded, \"produced an inccorect number of batches. expected %i, but yielded %i\" %(len(self), yielded)\n",
    "\n",
    "def trim_tensors(tsrs):\n",
    "    max_len = torch.max(torch.sum( (tsrs != 0  ), 1))\n",
    "    if max_len > 2: \n",
    "        tsrs = tsrs[:,:max_len]\n",
    "    return tsrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tq = tqdm_notebook(range(EPOCHS))\n",
    "for epoch in tq:\n",
    "#     train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    ran_sampler = data.RandomSampler(train_dataset)\n",
    "    len_sampler = LenMatchBatchSampler(ran_sampler, batch_size = 32, drop_last = False)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler = len_sampler)\n",
    "    \n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0.\n",
    "    lossf=None\n",
    "    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n",
    "    optimizer.zero_grad()\n",
    "    for i,(x_batch, y_batch) in tk0:\n",
    "#         x_batch=x_batch[0]\n",
    "#         optimizer.zero_grad()\n",
    "        x_batch = trim_tensors(x_batch)\n",
    "#         print(x_batch.shape)\n",
    "        y_pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
    "#         loss =  F.binary_cross_entropy_with_logits(y_pred,y_batch.to(device))\n",
    "#         print(y_pred,y_batch)\n",
    "        loss = custom_loss(y_pred,y_batch.to(device))\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
    "            optimizer.step()                            # Now we can do an optimizer step\n",
    "            optimizer.zero_grad()\n",
    "        if lossf:\n",
    "            lossf = 0.98*lossf+0.02*loss.item()\n",
    "        else:\n",
    "            lossf = loss.item()\n",
    "        tk0.set_postfix(loss = lossf)\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n",
    "    tq.set_postfix(avg_loss=avg_loss,avg_accuracy=avg_accuracy)\n",
    "\n",
    "# torch.save(model.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# # Run validation\n",
    "# The following 2 lines are not needed but show how to download the model for prediction\n",
    "# model = BertForSequenceClassification(bert_config,num_labels=len(y_columns))\n",
    "# model.load_state_dict(torch.load(output_model_file ))\n",
    "\n",
    "model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "model.eval()\n",
    "valid_preds = np.zeros((len(X_val)))\n",
    "valid = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long))\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle=False)\n",
    "\n",
    "tk0 = tqdm_notebook(valid_loader)\n",
    "for i,(x_batch,)  in enumerate(tk0):\n",
    "    pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
    "    valid_preds[i*32:(i+1)*32]=pred[:,0].detach().cpu().squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # From baseline kernel\n",
    "# # Evaluate the result\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]>=0.5\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "\n",
    "\n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, model_name):\n",
    "    subgroup_examples = df[df[subgroup]>=0.5]\n",
    "    return compute_auc((subgroup_examples[label]>=0.5), subgroup_examples[model_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[(df[subgroup]>=0.5) & (df[label]<0.5)]\n",
    "    non_subgroup_positive_examples = df[(df[subgroup]<0.5) & (df[label]>=0.5)]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label]>=0.5, examples[model_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[(df[subgroup]>=0.5) & (df[label]>=0.5)]\n",
    "    non_subgroup_negative_examples = df[(df[subgroup]<0.5) & (df[label]<0.5)]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label]>=0.5, examples[model_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset[dataset[subgroup]>=0.5])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bnsp_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>subgroup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.962241</td>\n",
       "      <td>0.890510</td>\n",
       "      <td>white</td>\n",
       "      <td>0.852428</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.963652</td>\n",
       "      <td>0.886001</td>\n",
       "      <td>black</td>\n",
       "      <td>0.854568</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.952497</td>\n",
       "      <td>0.927411</td>\n",
       "      <td>muslim</td>\n",
       "      <td>0.881146</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.923641</td>\n",
       "      <td>0.963243</td>\n",
       "      <td>jewish</td>\n",
       "      <td>0.888469</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.961794</td>\n",
       "      <td>0.912549</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.897133</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.935682</td>\n",
       "      <td>0.968008</td>\n",
       "      <td>christian</td>\n",
       "      <td>0.928870</td>\n",
       "      <td>1133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.954526</td>\n",
       "      <td>0.955213</td>\n",
       "      <td>female</td>\n",
       "      <td>0.929885</td>\n",
       "      <td>1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.967092</td>\n",
       "      <td>0.937968</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.930993</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.963711</td>\n",
       "      <td>0.946995</td>\n",
       "      <td>male</td>\n",
       "      <td>0.935525</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bnsp_auc  bpsn_auc      ...       subgroup_auc  subgroup_size\n",
       "7  0.962241  0.890510      ...           0.852428            679\n",
       "6  0.963652  0.886001      ...           0.854568            405\n",
       "5  0.952497  0.927411      ...           0.881146            604\n",
       "4  0.923641  0.963243      ...           0.888469            212\n",
       "2  0.961794  0.912549      ...           0.897133            297\n",
       "3  0.935682  0.968008      ...           0.928870           1133\n",
       "1  0.954526  0.955213      ...           0.929885           1440\n",
       "8  0.967092  0.937968      ...           0.930993            134\n",
       "0  0.963711  0.946995      ...           0.935525           1241\n",
       "\n",
       "[9 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.937016987208958"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'model1'\n",
    "test_df[MODEL_NAME]=torch.sigmoid(torch.tensor(valid_preds)).numpy()\n",
    "TOXICITY_COLUMN = 'target'\n",
    "bias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, 'target')\n",
    "bias_metrics_df\n",
    "get_final_metric(bias_metrics_df, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a checkpoint\n",
    "state = {'state_dict': model.state_dict(),'optimizer': optimizer.state_dict()}\n",
    "torch.save(state, 'bert_checkpoint_part1.bin')\n",
    "\n",
    "#model, optimizer, start_epoch, losslogger = load_checkpoint(model, optimizer, losslogger)\n",
    "#model = model.to(device)\n",
    "## now individually transfer the optimizer parts...\n",
    "#for state in optimizer.state.values():\n",
    "#    for k, v in state.items():\n",
    "#        if isinstance(v, torch.Tensor):\n",
    "#            state[k] = v.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
