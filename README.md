# Toxic comment analysis I
This project used LSTM to analysis comments' toxicity from Wikipedia, which originaly bring up by this kaggle competition
(https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge#description)

## 1. Notebook of LSTM implementation and exploratory data analysis
https://github.com/hhzzxx957/toxic_comment/blob/master/codes/improved-lstm-baseline-glove-dropout.ipynb

## 2. Examples about Esemble modeling

Here are the example codes used in the kaggle competition, input files are not included.
### (1) Out-of-folder(OOF) stacking
https://github.com/hhzzxx957/toxic_comment/blob/master/codes/oof_stack_regime.ipynb
### (2) Geomean and wighted average
https://github.com/hhzzxx957/toxic_comment/blob/master/codes/geomean.ipynb

## 3. A simple website to test comment's toxicity
http://hzx957.pythonanywhere.com/

# Toxic comment analysis II
This project used BERT to analysis comments' toxicity from Wikipedia, which originaly bring up by this kaggle competition
(https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/description)

## 1. Notebook of BERT implementation
https://github.com/hhzzxx957/toxic_comment/blob/master/codes/toxic-bert.ipynb
## 2. Blender
Blender of BERT, GPT2 and LSTM for final submittion
https://github.com/hhzzxx957/toxic_comment/blob/master/codes/BERT%20%2BGPT2%2B%20LSTM%20(final%20blender).ipynb
