{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "AUC: [0.98751373 0.98812735 0.98757516 0.98793401 0.98705573]\n",
      "severe_toxic\n",
      "AUC: [0.99173013 0.99183782 0.99092373 0.99139372 0.99257303]\n",
      "obscene\n",
      "AUC: [0.99506502 0.99498896 0.99563831 0.99543938 0.99482957]\n",
      "threat\n",
      "AUC: [0.9942114  0.99602995 0.99263837 0.99198302 0.99488323]\n",
      "insult\n",
      "AUC: [0.9894157  0.9888453  0.98990449 0.98941499 0.98867792]\n",
      "identity_hate\n",
      "AUC: [0.99096652 0.98860013 0.99067486 0.98913574 0.99272776]\n",
      "CV score: 0.9913578346912558\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "OOF stack regime\n",
    "Thanks for the great kernel from https://www.kaggle.com/hhstrand/oof-stacking-regime\n",
    "\n",
    "Explaination for OOF stack regime:\n",
    "This is a method of stacking different models, \n",
    "with the idea of \"combine the decisions from multiple models to improve the overall performance\"\n",
    "\n",
    "first step is similar to cross validation, but keep the prediction for each fold as out-of-folder prediction. \n",
    "Then use these predictions (from different model) as X_train, and correct result from original \n",
    "dataset as y_train, and prediction from test set (from different model) as X_test, \n",
    "to predict the final results. The main reason of using OOF is to avoid data leaking.\n",
    "\n",
    "\n",
    "Changes:\n",
    "Train oof (out of folder) prediction files to a new model by LGB\n",
    "1. add one more strategy\n",
    "First model: get new model first then predict final result\n",
    "Second model: predict final result by the model from each fold, then average\n",
    "\n",
    "2.Tuning hyperparameters for LGB\n",
    "\"\"\" \n",
    "\n",
    "#oof stack regime 1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning, module='sklearn')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#######################\n",
    "# FEATURE ENGINEERING #\n",
    "#######################\n",
    "\"\"\"\n",
    "Main function\n",
    "Input: pandas Series and a feature engineering function\n",
    "Output: pandas Series\n",
    "\"\"\"\n",
    "def engineer_feature(series, func, normalize=True):\n",
    "    feature = series.apply(func)\n",
    "       \n",
    "    if normalize:\n",
    "        feature = pd.Series(z_normalize(feature.values.reshape(-1,1)).reshape(-1,))\n",
    "    feature.name = func.__name__ \n",
    "    return feature\n",
    "\n",
    "\"\"\"\n",
    "Engineer features\n",
    "Input: pandas Series and a list of feature engineering functions\n",
    "Output: pandas DataFrame\n",
    "\"\"\"\n",
    "def engineer_features(series, funclist, normalize=True):\n",
    "    features = pd.DataFrame()\n",
    "    for func in funclist:\n",
    "        feature = engineer_feature(series, func, normalize)\n",
    "        features[feature.name] = feature\n",
    "    return features\n",
    "\n",
    "\"\"\"\n",
    "Normalizer\n",
    "Input: NumPy array\n",
    "Output: NumPy array\n",
    "\"\"\"\n",
    "scaler = StandardScaler()\n",
    "def z_normalize(data):\n",
    "    scaler.fit(data)\n",
    "    return scaler.transform(data)\n",
    "    \n",
    "\"\"\"\n",
    "Feature functions\n",
    "\"\"\"\n",
    "def asterix_freq(x):\n",
    "    return x.count('!')/len(x)\n",
    "\n",
    "def uppercase_freq(x):\n",
    "    return len(re.findall(r'[A-Z]',x))/len(x)\n",
    "    \n",
    "\"\"\"\n",
    "Import submission and OOF files\n",
    "\"\"\"\n",
    "def get_subs(nums):\n",
    "    subs = np.hstack([np.array(pd.read_csv(\"../input/trained-models/sub\" + str(num) + \".csv\")[LABELS]) for num in subnums])\n",
    "    oofs = np.hstack([np.array(pd.read_csv(\"../input/trained-models/oof\" + str(num) + \".csv\")[LABELS]) for num in subnums])\n",
    "    return subs, oofs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    train = pd.read_csv('../input/train.csv').fillna(' ')\n",
    "    test = pd.read_csv('../input/test.csv').fillna(' ')\n",
    "    sub = pd.read_csv('../input/sample_submission.csv')\n",
    "    INPUT_COLUMN = \"comment_text\"\n",
    "    LABELS = train.columns[2:]\n",
    "    \n",
    "    # Import submissions and OOF files\n",
    "    # 29: LightGBM trained on Fasttext (CV: 0.9765, LB: 0.9620)\n",
    "    # 51: Logistic regression with word and char n-grams (CV: 0.9858, LB: ?)\n",
    "    # 52: LSTM trained on Fasttext (CV: ?, LB: 0.9851)\n",
    "    subnums = [1,2,3,4,5,29,51,52]\n",
    "    subs, oofs = get_subs(subnums)\n",
    "    \n",
    "    # Engineer features\n",
    "    feature_functions = [len, asterix_freq, uppercase_freq]\n",
    "    features = [f.__name__ for f in feature_functions]\n",
    "    F_train = engineer_features(train[INPUT_COLUMN], feature_functions)\n",
    "    F_test = engineer_features(test[INPUT_COLUMN], feature_functions)\n",
    "    \n",
    "    X_train = np.hstack([F_train[features].as_matrix(), oofs])\n",
    "    X_test = np.hstack([F_test[features].as_matrix(), subs])    \n",
    "\n",
    "    stacker = lgb.LGBMClassifier(max_depth=3, metric=\"auc\", n_estimators=125, num_leaves=10, \n",
    "                                 boosting_type=\"gbdt\", learning_rate=0.1, feature_fraction=0.45, \n",
    "                                 colsample_bytree=0.45, bagging_fraction=0.8, bagging_freq=5, reg_lambda=0.2)\n",
    "    \n",
    "    # Fit and submit\n",
    "    scores = []\n",
    "    for label in LABELS:\n",
    "        print(label)\n",
    "        score = cross_val_score(stacker, X_train, train[label], cv=5, scoring='roc_auc')\n",
    "        print(\"AUC:\", score)\n",
    "        scores.append(np.mean(score))\n",
    "        stacker.fit(X_train, train[label])\n",
    "        sub[label] = stacker.predict_proba(X_test)[:,1]\n",
    "    print(\"CV score:\", np.mean(scores))\n",
    "    \n",
    "    sub.to_csv(\"oof_regime.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class toxic scores : \n",
      "\t Fold 1 : 0.988278 in 333 rounds\n",
      "\t Fold 2 : 0.986089 in 338 rounds\n",
      "\t Fold 3 : 0.988153 in 333 rounds\n",
      "\t Fold 4 : 0.986216 in 291 rounds\n",
      "\t Fold 5 : 0.988151 in 341 rounds\n",
      "\t Fold 6 : 0.986373 in 245 rounds\n",
      "\t Fold 7 : 0.988396 in 242 rounds\n",
      "\t Fold 8 : 0.988238 in 355 rounds\n",
      "\t Fold 9 : 0.986904 in 138 rounds\n",
      "\t Fold 10 : 0.988947 in 511 rounds\n",
      "full score : 0.987564\n",
      "Class severe_toxic scores : \n",
      "\t Fold 1 : 0.992248 in  73 rounds\n",
      "\t Fold 2 : 0.993084 in 140 rounds\n",
      "\t Fold 3 : 0.991702 in  50 rounds\n",
      "\t Fold 4 : 0.992143 in 158 rounds\n",
      "\t Fold 5 : 0.991564 in  45 rounds\n",
      "\t Fold 6 : 0.992328 in 205 rounds\n",
      "\t Fold 7 : 0.992173 in 278 rounds\n",
      "\t Fold 8 : 0.992309 in  36 rounds\n",
      "\t Fold 9 : 0.991183 in 196 rounds\n",
      "\t Fold 10 : 0.989662 in  46 rounds\n",
      "full score : 0.989639\n",
      "Class obscene scores : \n",
      "\t Fold 1 : 0.994383 in  98 rounds\n",
      "\t Fold 2 : 0.995753 in  39 rounds\n",
      "\t Fold 3 : 0.995501 in 302 rounds\n",
      "\t Fold 4 : 0.994613 in  38 rounds\n",
      "\t Fold 5 : 0.995866 in  57 rounds\n",
      "\t Fold 6 : 0.994576 in  43 rounds\n",
      "\t Fold 7 : 0.996066 in 154 rounds\n",
      "\t Fold 8 : 0.994624 in  51 rounds\n",
      "\t Fold 9 : 0.994232 in 138 rounds\n",
      "\t Fold 10 : 0.995509 in 123 rounds\n",
      "full score : 0.994015\n",
      "Class threat scores : \n",
      "\t Fold 1 : 0.997659 in  36 rounds\n",
      "\t Fold 2 : 0.995028 in  43 rounds\n",
      "\t Fold 3 : 0.986679 in 139 rounds\n",
      "\t Fold 4 : 0.994908 in  85 rounds\n",
      "\t Fold 5 : 0.995953 in 157 rounds\n",
      "\t Fold 6 : 0.995875 in  69 rounds\n",
      "\t Fold 7 : 0.995341 in 135 rounds\n",
      "\t Fold 8 : 0.993410 in  95 rounds\n",
      "\t Fold 9 : 0.993223 in  50 rounds\n",
      "\t Fold 10 : 0.996373 in 202 rounds\n",
      "full score : 0.980472\n",
      "Class insult scores : \n",
      "\t Fold 1 : 0.988011 in 106 rounds\n",
      "\t Fold 2 : 0.990630 in 111 rounds\n",
      "\t Fold 3 : 0.989571 in 208 rounds\n",
      "\t Fold 4 : 0.987501 in  35 rounds\n",
      "\t Fold 5 : 0.989936 in 254 rounds\n",
      "\t Fold 6 : 0.989034 in 140 rounds\n",
      "\t Fold 7 : 0.991280 in 273 rounds\n",
      "\t Fold 8 : 0.987944 in  59 rounds\n",
      "\t Fold 9 : 0.989168 in  59 rounds\n",
      "\t Fold 10 : 0.988523 in 289 rounds\n",
      "full score : 0.988213\n",
      "Class identity_hate scores : \n",
      "\t Fold 1 : 0.989008 in  42 rounds\n",
      "\t Fold 2 : 0.986575 in  56 rounds\n",
      "\t Fold 3 : 0.990722 in  74 rounds\n",
      "\t Fold 4 : 0.991700 in 116 rounds\n",
      "\t Fold 5 : 0.988113 in 136 rounds\n",
      "\t Fold 6 : 0.993202 in 139 rounds\n",
      "\t Fold 7 : 0.992294 in 109 rounds\n",
      "\t Fold 8 : 0.992989 in  96 rounds\n",
      "\t Fold 9 : 0.990913 in 163 rounds\n",
      "\t Fold 10 : 0.990453 in  51 rounds\n",
      "full score : 0.988942\n",
      "Total CV score is 0.9881410223849336\n",
      "total false CV score is 0.9914546766994321\n"
     ]
    }
   ],
   "source": [
    "#oof stack regime 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning, module='sklearn')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "#######################\n",
    "# FEATURE ENGINEERING #\n",
    "#######################\n",
    "\"\"\"\n",
    "Main function\n",
    "Input: pandas Series and a feature engineering function\n",
    "Output: pandas Series\n",
    "\"\"\"\n",
    "def engineer_feature(series, func, normalize=True):\n",
    "    feature = series.apply(func)\n",
    "       \n",
    "    if normalize:\n",
    "        feature = pd.Series(z_normalize(feature.values.reshape(-1,1)).reshape(-1,))\n",
    "    feature.name = func.__name__ \n",
    "    return feature\n",
    "\n",
    "\"\"\"\n",
    "Engineer features\n",
    "Input: pandas Series and a list of feature engineering functions\n",
    "Output: pandas DataFrame\n",
    "\"\"\"\n",
    "def engineer_features(series, funclist, normalize=True):\n",
    "    features = pd.DataFrame()\n",
    "    for func in funclist:\n",
    "        feature = engineer_feature(series, func, normalize)\n",
    "        features[feature.name] = feature\n",
    "    return features\n",
    "\n",
    "\"\"\"\n",
    "Normalizer\n",
    "Input: NumPy array\n",
    "Output: NumPy array\n",
    "\"\"\"\n",
    "scaler = StandardScaler()\n",
    "def z_normalize(data):\n",
    "    scaler.fit(data)\n",
    "    return scaler.transform(data)\n",
    "    \n",
    "\"\"\"\n",
    "Feature functions\n",
    "\"\"\"\n",
    "def asterix_freq(x):\n",
    "    return x.count('!')/len(x)\n",
    "\n",
    "def uppercase_freq(x):\n",
    "    return len(re.findall(r'[A-Z]',x))/len(x)\n",
    "    \n",
    "\"\"\"\n",
    "Import submission and OOF files\n",
    "\"\"\"\n",
    "def get_subs(nums):\n",
    "    subs = np.hstack([np.array(pd.read_csv(\"../input/trained-models/sub\" + str(num) + \".csv\")[LABELS]) for num in nums])\n",
    "    oofs = np.hstack([np.array(pd.read_csv(\"../input/trained-models/oof\" + str(num) + \".csv\")[LABELS]) for num in nums])\n",
    "    return subs, oofs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    train = pd.read_csv('../input/train.csv').fillna(' ')\n",
    "    test = pd.read_csv('../input/test.csv').fillna(' ')\n",
    "    submission = pd.read_csv('../input/sample_submission.csv')\n",
    "    INPUT_COLUMN = \"comment_text\"\n",
    "    LABELS = train.columns[2:]\n",
    "    \n",
    "    # Import submissions and OOF files\n",
    "    # 29: LightGBM trained on Fasttext (CV: 0.9765, LB: 0.9620)\n",
    "    # 51: Logistic regression with word and char n-grams (CV: 0.9858, LB: ?)\n",
    "    # 52: LSTM trained on Fasttext (CV: ?, LB: 0.9851)\n",
    "    subnums = [1,2,3,4,5,29,51,52]\n",
    "    subs, oofs = get_subs(subnums)\n",
    "    \n",
    "    # Engineer features\n",
    "    feature_functions = [len, asterix_freq, uppercase_freq]\n",
    "    features = [f.__name__ for f in feature_functions]\n",
    "    F_train = engineer_features(train[INPUT_COLUMN], feature_functions)\n",
    "    F_test = engineer_features(test[INPUT_COLUMN], feature_functions)\n",
    "    \n",
    "    X_train = np.hstack([F_train[features].as_matrix(), oofs])\n",
    "    X_test = np.hstack([F_test[features].as_matrix(), subs])\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        'metric': {'auc'},\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"verbosity\": -1,\n",
    "        \"num_threads\": 4,\n",
    "        \"max_depth\":3,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\":5,\n",
    "        #\"colsample_bytree\":0.45,\n",
    "        \"feature_fraction\": 0.45,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"num_leaves\": 3,\n",
    "        \"verbose\": -1,\n",
    "        #\"min_split_gain\": .1,\n",
    "        \"reg_alpha\": .3\n",
    "    }\n",
    "    # Now go through folds\n",
    "    # I use K-Fold for reasons described here : \n",
    "    # https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/49964\n",
    "    train.drop(\"comment_text\",axis=1,inplace=True)\n",
    "    scores = []\n",
    "    scores_false = []\n",
    "    folds = KFold(n_splits=10, shuffle=True, random_state=233)\n",
    "    trn_lgbset = lgb.Dataset(X_train, free_raw_data=False)\n",
    "    del X_train\n",
    "    gc.collect()\n",
    "    for class_name in LABELS:\n",
    "        print(\"Class %s scores : \" % class_name)\n",
    "        class_pred = np.zeros(len(train))\n",
    "        train_target = train[class_name]\n",
    "        trn_lgbset.set_label(train_target.values)\n",
    "        submission[class_name] = np.zeros(len(X_test))\n",
    "        lgb_rounds = 1000\n",
    "        score_temp = 0;\n",
    "        for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, train_target)):\n",
    "            watchlist = [\n",
    "                trn_lgbset.subset(trn_idx),\n",
    "                trn_lgbset.subset(val_idx)\n",
    "            ]\n",
    "            # Train lgb l1\n",
    "            model = lgb.train(\n",
    "                params=params,\n",
    "                train_set=watchlist[0],\n",
    "                num_boost_round=lgb_rounds,\n",
    "                valid_sets=watchlist,\n",
    "                early_stopping_rounds=50,\n",
    "                verbose_eval=0\n",
    "            )\n",
    "            class_pred[val_idx] = model.predict(trn_lgbset.data[val_idx], num_iteration=model.best_iteration)\n",
    "            # sum all the predictions from each fold\n",
    "            submission[class_name] = submission[class_name] + model.predict(X_test, num_iteration=model.best_iteration)\n",
    "            score = roc_auc_score(train_target.values[val_idx], class_pred[val_idx])\n",
    "            score_temp += score\n",
    "            print(\"\\t Fold %d : %.6f in %3d rounds\" % (n_fold + 1, score, model.best_iteration))\n",
    "        submission[class_name] = submission[class_name] / folds.n_splits  \n",
    "        print(\"full score : %.6f\" % roc_auc_score(train_target, class_pred))\n",
    "        scores.append(roc_auc_score(train_target, class_pred))\n",
    "        scores_false.append(score_temp / 10)\n",
    "        train[class_name + \"_oof\"] = class_pred\n",
    "\n",
    "\n",
    "    print('Total CV score is {}'.format(np.mean(scores)))\n",
    "    print(\"total false CV score is {}\".format(np.mean(scores_false)))\n",
    "    submission.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished to load test predictions.\n",
      "Finished to load OOF predictions.\n"
     ]
    }
   ],
   "source": [
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "# mypath = '../input/single_model_predictions_03092018/'\n",
    "# classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
    "#        'identity_hate']\n",
    "# test_files = [f for f in listdir(mypath) if isfile(join(mypath, f)) and f.endswith('test_oof.csv')]\n",
    "# test_df = []\n",
    "# for i, file in enumerate(test_files):\n",
    "#     df = pd.read_csv(mypath+file)\n",
    "#     temp = df[df['fold_id']==0].drop('fold_id', axis = 1).copy()\n",
    "#     temp[classes] = 0\n",
    "#     for i in np.arange(0, df['fold_id'].max()):\n",
    "#         temp[classes] += df.loc[df['fold_id']==i, classes].values/df['fold_id'].max()\n",
    "#     test_df.append(temp)\n",
    "# print('Finished to load test predictions.')\n",
    "# train_files = [f for f in listdir(mypath) if isfile(join(mypath, f)) and f.endswith('train_oof.csv')]\n",
    "# train_oof = []\n",
    "# for i, file in enumerate(train_files):\n",
    "#     train_oof.append(pd.read_csv(mypath+file))\n",
    "# print('Finished to load OOF predictions.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
